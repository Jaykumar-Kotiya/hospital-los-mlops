import json
import numpy as np
import joblib
import streamlit as st
import pandas as pd
from pathlib import Path

ROOT = Path(__file__).resolve().parents[1]
PROCESSED = ROOT / "data" / "processed"
MODELS = ROOT / "models"
REPORTS = ROOT / "reports"
FIGS = REPORTS / "figures"

LOS_MIN, LOS_MAX = 1.0, 14.0

st.set_page_config(page_title="Hospital LOS Predictor", layout="wide")


@st.cache_resource
def load_assets():
    X = np.load(PROCESSED / "X.npy")
    y = np.load(PROCESSED / "y.npy")

    # pick newest advanced model
    candidates = sorted(MODELS.glob("xgboost_los_model_advanced_v2_*.joblib"))
    if not candidates:
        candidates = sorted(MODELS.glob("xgboost_los_model_advanced_*.joblib"))
    if not candidates:
        raise FileNotFoundError("No advanced model found in models/. Train model first.")

    model_path = candidates[-1]
    model = joblib.load(model_path)

    return X, y, model, model_path


def clip_los(pred: float) -> float:
    return float(np.clip(pred, LOS_MIN, LOS_MAX))


def find_first_existing(paths):
    for p in paths:
        if p.exists():
            return p
    return None


# ---------- Header ----------
st.title("üè• Hospital Length of Stay (LOS) Predictor")
st.caption(
    "Enterprise demo: XGBoost regression ‚Ä¢ cost-safe MLOps workflow ‚Ä¢ SHAP explainability ‚Ä¢ local UI"
)

X, y, model, model_path = load_assets()

# Try to load latest training report (optional)
metrics_files = sorted(REPORTS.glob("training_metrics_advanced_v2_*.json"))
latest_metrics = None
if metrics_files:
    try:
        latest_metrics = json.loads(metrics_files[-1].read_text())
    except Exception:
        latest_metrics = None

# KPI row
kpi1, kpi2, kpi3, kpi4 = st.columns(4)
kpi1.metric("Samples", f"{X.shape[0]:,}")
kpi2.metric("Features", f"{X.shape[1]}")
if latest_metrics:
    kpi3.metric("Val MAE (days)", f"{latest_metrics.get('val_mae', 0):.3f}")
    kpi4.metric("Val RMSE (days)", f"{latest_metrics.get('val_rmse', 0):.3f}")
else:
    kpi3.metric("Val MAE (days)", "‚Äî")
    kpi4.metric("Val RMSE (days)", "‚Äî")

st.divider()

# ---------- Tabs ----------
tab_predict, tab_explain, tab_docs = st.tabs(["üîÆ Predict", "üß† Explain (SHAP)", "üìå Project Notes"])

# ======================
# TAB: PREDICT
# ======================
with tab_predict:
    left, right = st.columns([1, 1])

    with left:
        st.subheader("Pick a patient sample")
        idx = st.number_input(
            "Row index (0..max)",
            min_value=0,
            max_value=int(X.shape[0] - 1),
            value=50000,
            step=1,
        )

        raw_pred = float(model.predict(X[idx:idx+1])[0])
        final_pred = clip_los(raw_pred)

        st.metric("Predicted LOS (clipped)", f"{final_pred:.2f} days")
        st.caption(f"Raw model output: {raw_pred:.4f} | Clipping: [{LOS_MIN}, {LOS_MAX}] days")

        st.write(f"True LOS (label): **{int(y[idx])} days**")

        # quick error for this point
        abs_err = abs(final_pred - float(y[idx]))
        st.write(f"Absolute error for this sample: **{abs_err:.2f} days**")

    with right:
        st.subheader("Quick distribution check (random sample)")
        n = st.slider("Sample size for histogram", min_value=200, max_value=5000, value=1000, step=200)
        rng = np.random.default_rng(42)
        pick = rng.choice(X.shape[0], size=min(n, X.shape[0]), replace=False)

        preds = model.predict(X[pick])
        preds = np.clip(preds, LOS_MIN, LOS_MAX)

        st.write("Histogram of predicted LOS (clipped)")
        st.bar_chart(np.histogram(preds, bins=14, range=(1, 14))[0])

        st.write("Histogram of true LOS")
        st.bar_chart(np.histogram(y[pick], bins=14, range=(1, 14))[0])

        st.caption("This helps show bias (e.g., overpredicting or underpredicting short stays).")

# ======================
# TAB: EXPLAIN (SHAP)
# ======================
with tab_explain:
    st.subheader("Explainability (SHAP)")
    st.write("These assets are generated by `python src/explainability/shap_summary.py` and saved under `reports/`.")

    # ‚úÖ Top feature table
    st.divider()
    st.subheader("Top Drivers of LOS (Global Explainability Summary)")
    st.write(
        "Ranked by **mean absolute SHAP value** (higher = more impact on the model‚Äôs LOS prediction). "
        "This is a standard enterprise explainability summary."
    )

    top_csv = REPORTS / "shap_top_features.csv"
    if top_csv.exists():
        df_top = pd.read_csv(top_csv)
        st.dataframe(df_top, use_container_width=True)
        st.download_button(
            "Download top feature table (CSV)",
            data=top_csv.read_bytes(),
            file_name="shap_top_features.csv",
        )
    else:
        st.warning("Top feature table not found. Run: `python src/explainability/shap_summary.py`")

    # ‚úÖ SHAP summary plots
    st.divider()
    st.subheader("Global SHAP Plots")

    bar_path = find_first_existing([FIGS / "shap_summary_bar.png"])
    bee_path = find_first_existing([FIGS / "shap_summary_beeswarm.png"])

    colA, colB = st.columns(2)
    with colA:
        if bar_path:
            st.image(str(bar_path), caption="Global Importance (Bar)", use_container_width=True)
            st.download_button("Download bar plot", data=bar_path.read_bytes(), file_name=bar_path.name)
        else:
            st.warning("Missing shap_summary_bar.png")

    with colB:
        if bee_path:
            st.image(str(bee_path), caption="Impact Distribution (Beeswarm)", use_container_width=True)
            st.download_button("Download beeswarm plot", data=bee_path.read_bytes(), file_name=bee_path.name)
        else:
            st.warning("Missing shap_summary_beeswarm.png")

    # ‚úÖ Local explanation plots
    st.divider()
    st.subheader("Per-Patient Explanation (Local)")

    wf_path = find_first_existing([FIGS / "shap_waterfall_example.png"])
    force_html_path = find_first_existing([FIGS / "shap_force_example.html"])

    if wf_path:
        st.image(str(wf_path), caption="Waterfall Explanation (Single Example)", use_container_width=True)
        st.download_button("Download waterfall plot", data=wf_path.read_bytes(), file_name=wf_path.name)
    else:
        st.info("Missing shap_waterfall_example.png")

    if force_html_path:
        st.subheader("Force Plot (Interactive)")
        st.download_button("Download force plot HTML", data=force_html_path.read_bytes(), file_name=force_html_path.name)
        try:
            st.components.v1.html(force_html_path.read_text(), height=320, scrolling=True)
        except Exception:
            st.info("Force HTML exists but cannot render inside this browser. Download and open locally.")
    else:
        st.info("Missing shap_force_example.html")

    # ‚úÖ Dependence plots
    st.divider()
    st.subheader("Feature Behavior (Dependence Plots)")

    dep1 = find_first_existing([FIGS / "shap_dependence_top1.png"])
    dep2 = find_first_existing([FIGS / "shap_dependence_top2.png"])

    col1, col2 = st.columns(2)
    with col1:
        if dep1:
            st.image(str(dep1), caption="Dependence Plot (Top feature #1)", use_container_width=True)
            st.download_button("Download dependence plot #1", data=dep1.read_bytes(), file_name=dep1.name)
        else:
            st.info("Missing shap_dependence_top1.png")

    with col2:
        if dep2:
            st.image(str(dep2), caption="Dependence Plot (Top feature #2)", use_container_width=True)
            st.download_button("Download dependence plot #2", data=dep2.read_bytes(), file_name=dep2.name)
        else:
            st.info("Missing shap_dependence_top2.png")

# ======================
# TAB: DOCS
# ======================
with tab_docs:
    st.subheader("What this demo proves")
    st.markdown(
        """
- ‚úÖ **Enterprise ML workflow**: preprocessing ‚Üí training ‚Üí evaluation ‚Üí explainability ‚Üí inference UI  
- ‚úÖ **Healthcare regression**: LOS prediction with realistic output handling (clipping)  
- ‚úÖ **Reproducibility**: artifacts stored locally + reports versioned  
- ‚úÖ **Explainability**: SHAP global + local insights surfaced via UI  
        """
    )

    st.subheader("Artifacts")
    st.write(f"Model loaded: `{model_path.name}`")
    if latest_metrics:
        st.write("Latest training report:")
        st.json(latest_metrics)
    else:
        st.info("No training report JSON found under reports/.")

    st.subheader("Next enterprise upgrades")
    st.markdown(
        """
- Add **deployment mode** (Local vs Vertex Endpoint)  
- Add **drift checks** + monitoring dashboard  
- Add **scheduled retraining** + model versioning strategy  
- Add **feature name mapping in UI tables** (already implemented in preprocessing)
        """
    )
